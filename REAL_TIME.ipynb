{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac09667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP PATHS\n",
    "\n",
    "WORKSPACE_PATH = 'workspace'\n",
    "APIMODEL_PATH = 'models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = PRETRAINED_MODEL_PATH+'/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d217b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved_model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea0490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the location accordingly\n",
    "detection_model = tf.saved_model.load(MODEL_PATH+'/model/inference_graph/saved_model')\n",
    "\n",
    "#Loading the label_map\n",
    "PATH_TO_LABELS = ANNOTATION_PATH+'/anotasi/label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bce49f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'id': 1, 'name': 'car'},\n",
       " 2: {'id': 2, 'name': 'motorcycle'},\n",
       " 3: {'id': 3, 'name': 'person'},\n",
       " 4: {'id': 4, 'name': 'pothole'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e648baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  # Run inference\n",
    "  model_fn = model.signatures['serving_default']\n",
    "  output_dict = model_fn(input_tensor)\n",
    "#   print(output_dict)\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "\n",
    "  # detection_classes should be ints.\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "#   print(output_dict['detection_classes'])\n",
    "  # Handle models with masks:\n",
    "  if 'detection_masks' in output_dict:\n",
    "    # Reframe the the bbox mask to the image size.\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.8,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "  return output_dict\n",
    "\n",
    "\n",
    "def show_inference(model, image_np):\n",
    "  # Actual detection.\n",
    "  output_dict = run_inference_for_single_image(model, image_np)\n",
    "\n",
    "#   print(category_index)\n",
    "  # Visualization of the results of a detection.\n",
    "  final_img =vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          output_dict['detection_boxes'],\n",
    "          output_dict['detection_classes'],\n",
    "          output_dict['detection_scores'],\n",
    "          category_index,      \n",
    "          instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=0.50, \n",
    "          line_thickness=8)\n",
    "  list_classes = output_dict['detection_classes'].tolist()\n",
    "  list_scores = output_dict['detection_scores'].tolist()\n",
    "  index_max_score = list_scores.index(max(output_dict['detection_scores']))\n",
    "  if list_scores[0] > 0.50:\n",
    "      print(category_index[list_classes[0]]['name'], list_scores[0]*100)\n",
    "  return(final_img)\n",
    "#   display(Image.fromarray(image_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d277767",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from threading import Thread\n",
    "# import time\n",
    "\n",
    "# class ThreadedCamera(object):\n",
    "#     def __init__(self, source = 0):\n",
    "\n",
    "#         self.capture = cv2.VideoCapture(source)\n",
    "\n",
    "#         self.thread = Thread(target = self.update, args = ())\n",
    "#         self.thread.daemon = True\n",
    "#         self.thread.start()\n",
    "\n",
    "#         self.status = False\n",
    "#         self.frame  = None\n",
    "\n",
    "#     def update(self):\n",
    "#         while True:\n",
    "#             if self.capture.isOpened():\n",
    "#                 (self.status, self.frame) = self.capture.read()\n",
    "\n",
    "#     def grab_frame(self):\n",
    "#         if self.status:\n",
    "#             return self.frame\n",
    "#         return None\n",
    "# if __name__ == '__main__':\n",
    "# #     stream_link = 'tcp://193.168.0.1:6200/'\n",
    "#     vid_link= 'workspace/images/motorcycle/melintas.mp4'\n",
    "#     streamer = ThreadedCamera(vid_link)\n",
    "    \n",
    "#     prev_frame_time = 0\n",
    "#     prev_frame_time = 0\n",
    "\n",
    "#     while True:\n",
    "#         img = streamer.grab_frame()\n",
    "#         if img is not None:\n",
    "#             img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "#             final_img = show_inference(detection_model,img)\n",
    "            \n",
    "#             new_frame_time = time.time()\n",
    "#             fps = 1/(new_frame_time-prev_frame_time)\n",
    "#             prev_frame_time = new_frame_time\n",
    "#             fps = str(fps)\n",
    "# #             print('fps: ',fps)\n",
    "    \n",
    "#             final_img = cv2.cvtColor(final_img,cv2.COLOR_RGB2BGR)\n",
    "#             cv2.imshow('object detection', cv2.resize(final_img, (1000, 600)))\n",
    "\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     streamer.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cd0fe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person 52.444714307785034\n",
      "person 55.41685223579407\n",
      "person 54.80864644050598\n",
      "person 57.227784395217896\n",
      "person 51.429712772369385\n",
      "person 62.01736927032471\n",
      "person 57.4243426322937\n",
      "person 52.92897820472717\n",
      "person 50.60076117515564\n",
      "person 57.61599540710449\n",
      "motorcycle 71.15488648414612\n",
      "motorcycle 88.61511945724487\n",
      "motorcycle 81.91692233085632\n",
      "motorcycle 76.45947337150574\n",
      "motorcycle 58.24745297431946\n",
      "motorcycle 67.30813980102539\n",
      "motorcycle 91.69935584068298\n",
      "motorcycle 94.97051239013672\n",
      "motorcycle 96.89061045646667\n",
      "motorcycle 89.71806168556213\n",
      "motorcycle 91.15243554115295\n",
      "motorcycle 89.53891396522522\n",
      "motorcycle 81.00905418395996\n",
      "motorcycle 82.26399421691895\n",
      "motorcycle 95.45232057571411\n",
      "motorcycle 94.68223452568054\n",
      "motorcycle 89.72479104995728\n",
      "motorcycle 96.35006189346313\n",
      "motorcycle 94.05617713928223\n",
      "motorcycle 89.423668384552\n",
      "motorcycle 87.45128512382507\n",
      "motorcycle 84.72368717193604\n",
      "motorcycle 84.7745418548584\n",
      "motorcycle 73.48418235778809\n",
      "motorcycle 73.03702235221863\n",
      "motorcycle 75.79981684684753\n",
      "motorcycle 63.009655475616455\n",
      "motorcycle 59.32798385620117\n",
      "motorcycle 63.12296390533447\n",
      "motorcycle 82.86428451538086\n",
      "motorcycle 62.31348514556885\n",
      "motorcycle 58.42798352241516\n",
      "motorcycle 58.50416421890259\n",
      "motorcycle 64.30726647377014\n",
      "motorcycle 64.94877934455872\n",
      "motorcycle 60.550326108932495\n",
      "motorcycle 54.10045385360718\n",
      "motorcycle 81.49985074996948\n",
      "motorcycle 64.5322322845459\n",
      "motorcycle 62.53514289855957\n",
      "motorcycle 75.3930389881134\n",
      "motorcycle 78.58694791793823\n",
      "motorcycle 55.797529220581055\n",
      "motorcycle 56.88948631286621\n",
      "motorcycle 87.41253614425659\n",
      "motorcycle 80.31982779502869\n",
      "motorcycle 67.50011444091797\n",
      "motorcycle 80.58525919914246\n",
      "motorcycle 86.81598901748657\n",
      "motorcycle 84.75762009620667\n",
      "motorcycle 72.19589352607727\n",
      "motorcycle 80.1504135131836\n",
      "motorcycle 86.25762462615967\n",
      "motorcycle 92.87992715835571\n",
      "motorcycle 88.27917575836182\n",
      "motorcycle 93.22479367256165\n",
      "motorcycle 89.60059881210327\n",
      "motorcycle 92.95528531074524\n",
      "motorcycle 90.04137516021729\n",
      "motorcycle 88.3927047252655\n",
      "motorcycle 85.86278557777405\n",
      "motorcycle 79.96196746826172\n",
      "motorcycle 88.45404386520386\n",
      "motorcycle 84.91926789283752\n",
      "motorcycle 61.396217346191406\n",
      "motorcycle 69.66831684112549\n",
      "motorcycle 74.96227025985718\n",
      "motorcycle 65.84554314613342\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5464\\652300618.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mfinal_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshow_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetection_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(\"workspace/images/motorcycle/melintas.mp4\")\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while 1:\n",
    "    _,img = cap.read()\n",
    "    \n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    final_img = show_inference(detection_model,img)\n",
    "    \n",
    "    final_img = cv2.cvtColor(final_img,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imshow('object detection', cv2.resize(final_img, (1000, 600)))\n",
    "#     cv2.imshow('img',img)\n",
    "#     cv2.imshow('Object Detection',final_img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc87592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
